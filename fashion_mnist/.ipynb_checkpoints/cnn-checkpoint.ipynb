{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# these seeds are both required for reproducibility\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dropout, Input\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "offset must be non-negative and no greater than buffer length (0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-56bcb9583890>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load and scale the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#The data comes as 28 x 28, so we are going to flatten it to 28^2 = 784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\datasets\\fashion_mnist.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlbpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlbpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimgpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: offset must be non-negative and no greater than buffer length (0)"
     ]
    }
   ],
   "source": [
    "# Load and scale the data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#The data comes as 28 x 28, so we are going to flatten it to 28^2 = 784 \n",
    "x_train = x_train.reshape(x_train.shape[0],784)\n",
    "\n",
    "#Next we scale it to a 0 to 1 scale as it is in a 0-255 scale (for grayscale)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "\n",
    "#The y train is the category of the image, 0-9 so we will make it a categorical variable\n",
    "'''\n",
    "0   T-shirt/top\n",
    "1   Trouser\n",
    "2   Pullover\n",
    "3   Dress\n",
    "4   Coat\n",
    "5   Sandal\n",
    "6   Shirt\n",
    "7   Sneaker\n",
    "8   Bag\n",
    "9   Ankle Boot\n",
    "'''\n",
    "y_train = to_categorical(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(keep_prob=0.5, optimizer='adam'):\n",
    "    inputs = Input(shape=(784,), name=\"input\")\n",
    "    \n",
    "    #Convolution 1\n",
    "    conv1 = Conv2D(512, kernel_size=(3,3), activation=\"relu\", name=\"conv_1\")(inputs)\n",
    "    #batch1 = BatchNormalization(name=\"batch_norm_1\")(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), name=\"pool_1\")(conv1)\n",
    "\n",
    "    #Convolution 2\n",
    "    conv2 = Conv2D(256, kernel_size=(3,3), activation=\"relu\", name=\"conv_2\")(pool1)\n",
    "    #batch2 = BatchNormalization(name=\"batch_norm_2\")(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), name=\"pool_2\")(conv2)\n",
    "    \n",
    "    #Convolution 3\n",
    "    conv3 = Conv2D(128, kernel_size=(3,3), activation=\"relu\", name=\"conv_3\")(pool2)\n",
    "    #batch3 = BatchNormalization(name=\"batch_norm_3\")(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), name=\"pool_3\")(conv3)\n",
    "    \n",
    "    #Convolution 4\n",
    "    conv4 = Conv2D(64, kernel_size=(3,3), activation=\"relu\", name=\"conv_4\")(pool3)\n",
    "    #batch4 = BatchNormalization(name=\"batch_norm_4\")(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), name=\"pool_4\")(conv4)\n",
    "    \n",
    "    #Fully Connected Layer\n",
    "    flatten = Flatten()(pool4)\n",
    "    fc1 = Dense(1024, activation=\"relu\", name=\"fc_1\")(flatten)\n",
    "    \n",
    "    #output\n",
    "    output=Dense(10, activation=\"softmax\", name =\"softmax\")(fc1)\n",
    "    \n",
    "    \n",
    "    # finalize and compile\n",
    "    model = Model(inputs=inputs, outputs=prediction)\n",
    "    model.compile(optimizer=optimizer', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(name):\n",
    "    tensorboard_callback = TensorBoard(log_dir=os.path.join(os.getcwd(), \"tensorboard_log\", name), write_graph=True, write_grads=False)\n",
    "    checkpoint_callback = ModelCheckpoint(filepath=\"./model-weights-\" + name + \".{epoch:02d}-{val_loss:.6f}.hdf5\", monitor='val_loss',\n",
    "                                          verbose=0, save_best_only=True)\n",
    "    return [tensorboard_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hyperparameters():\n",
    "    batches = [10,20,30,40,50]\n",
    "    optimizers = ['rmsprop', 'adam', 'adadelta']\n",
    "    dropout = np.linspace(0.1, 0.5, 5)\n",
    "    return (\"batch_size\": batches, \"optimizer\": optimizers, \"keep_prob\": dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data(train_data_dir, val_data_dir, img_width=299, img_height=299, batch_size=16):\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        val_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, train_generator, val_generator, batch_size, epochs, name):\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.n // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.n // batch_size,\n",
    "        callbacks=create_callbacks(name=name),\n",
    "        verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, val_generator, batch_size):\n",
    "    scores = model.evaluate_generator(val_generator, steps=val_generator.n // batch_size)\n",
    "    print(\"Loss: \" + str(scores[0]) + \" Accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load configuration class\n",
    "This has all our model configuration parameters in it.  It's defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "If everything is setup correctly, this method will print  \n",
    "\"  \n",
    "Found 1097 images belonging to 10 classes.  \n",
    "Found 272 images belonging to 10 classes.  \n",
    "\"  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1097 images belonging to 10 classes.\n",
      "Found 272 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator = setup_data(config.data_dir, config.val_dir, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile your model and print a summary\n",
    "\n",
    "Your network should look like this.\n",
    "\n",
    "\n",
    "input (InputLayer)           (None, 299, 299, 3)       0         \n",
    "_________________________________________________________________\n",
    "conv_1 (Conv2D)              (None, 297, 297, 128)     3584      \n",
    "_________________________________________________________________\n",
    "pool_1 (MaxPooling2D)        (None, 148, 148, 128)     0         \n",
    "_________________________________________________________________\n",
    "conv_2 (Conv2D)              (None, 146, 146, 64)      73792     \n",
    "_________________________________________________________________\n",
    "pool_2 (MaxPooling2D)        (None, 73, 73, 64)        0         \n",
    "_________________________________________________________________\n",
    "conv_3 (Conv2D)              (None, 71, 71, 32)        18464     \n",
    "_________________________________________________________________\n",
    "pool_3 (MaxPooling2D)        (None, 35, 35, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv_4 (Conv2D)              (None, 33, 33, 16)        4624      \n",
    "_________________________________________________________________\n",
    "pool_4 (MaxPooling2D)        (None, 16, 16, 16)        0         \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 4096)              0         \n",
    "_________________________________________________________________\n",
    "fc1 (Dense)                  (None, 1024)              4195328   \n",
    "_________________________________________________________________\n",
    "softmax (Dense)              (None, 10)                10250     \n",
    "\n",
    "Total params: 4,306,042\n",
    "Trainable params: 4,306,042\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 297, 297, 128)     3584      \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 148, 148, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 146, 146, 64)      73792     \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 71, 71, 32)        18464     \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling2D)        (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 33, 33, 16)        4624      \n",
      "_________________________________________________________________\n",
      "pool_4 (MaxPooling2D)        (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc_1 (Dense)                 (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "softmax (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 4,306,042\n",
      "Trainable params: 4,306,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "You're most certainly going to want a GPU to train this model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit_model(model, train_generator, val_generator,\n",
    "                  batch_size=config.batch_size,\n",
    "                  epochs=config.epochs_without_transfer_learning,\n",
    "                  name=\"without_transfer_learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your model.\n",
    "eval_model(model, val_generator, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 100/100\n",
    "36/36 [==============================] - 55s 2s/step - loss: 1.8918e-06 - acc: 1.0000 - val_loss: 3.2057 - val_acc: 0.6397   \n",
    "\n",
    "Loss: 3.19792111714681 Accuracy: 0.6407407455974155\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model weights\n",
    "model.save(\"no_transfer_learning_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
