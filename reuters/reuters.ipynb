{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import reuters\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  [1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "Training label:  3\n",
      "Length of training data 8982\n",
      "Length of test data 2246\n"
     ]
    }
   ],
   "source": [
    "#Look at a small part of the data\n",
    "print('Training data: ', x_train[0])\n",
    "print('Training label: ', y_train[0])\n",
    "print('Length of training data', len(x_train))\n",
    "print('Length of test data', len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13074"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "#Check to see what index the word sport is, a rudimentary test of the index loading\n",
    "word_index[\"sport\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word at index 13074 is:  sport\n",
      "There are 30980 words in the word index\n"
     ]
    }
   ],
   "source": [
    "#The index is organized to look up the integer value, it would be better to look up the key\n",
    "integer_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# Now we can search for the word that aligns to a certain key, we looked up sport before so lets check that index\n",
    "print('The word at index 13074 is: ',integer_word_index[13074])\n",
    "\n",
    "#how many different words are in the index\n",
    "print('There are', len(integer_word_index)+1, 'words in the word index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "10000\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "#Max words in an article\n",
    "max_words = 10000\n",
    "#46 labels\n",
    "LABEL_DIMENSIONS = max(y_train)+1\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, LABEL_DIMENSIONS)\n",
    "y_test = keras.utils.to_categorical(y_test, LABEL_DIMENSIONS)\n",
    "\n",
    "print(x_train[0])\n",
    "print(len(x_train[0]))\n",
    "\n",
    "print(y_train[0])\n",
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 64)                640064    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(10000, )))\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(LABEL_DIMENSIONS, activation=tf.nn.softmax))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/10\n",
      "8083/8083 [==============================] - 2s 286us/step - loss: 1.7727 - acc: 0.6316 - val_loss: 1.2335 - val_acc: 0.7442\n",
      "Epoch 2/10\n",
      "8083/8083 [==============================] - 2s 231us/step - loss: 0.7982 - acc: 0.8221 - val_loss: 1.0257 - val_acc: 0.7753\n",
      "Epoch 3/10\n",
      "8083/8083 [==============================] - 2s 234us/step - loss: 0.4365 - acc: 0.9041 - val_loss: 1.0040 - val_acc: 0.8065\n",
      "Epoch 4/10\n",
      "8083/8083 [==============================] - 2s 233us/step - loss: 0.2862 - acc: 0.9388 - val_loss: 0.9985 - val_acc: 0.8087\n",
      "Epoch 5/10\n",
      "8083/8083 [==============================] - 2s 239us/step - loss: 0.2133 - acc: 0.9508 - val_loss: 1.0215 - val_acc: 0.7942\n",
      "Epoch 6/10\n",
      "8083/8083 [==============================] - 2s 249us/step - loss: 0.1854 - acc: 0.9547 - val_loss: 1.0112 - val_acc: 0.8031\n",
      "Epoch 7/10\n",
      "8083/8083 [==============================] - 2s 267us/step - loss: 0.1588 - acc: 0.9558 - val_loss: 1.0993 - val_acc: 0.7775\n",
      "Epoch 8/10\n",
      "8083/8083 [==============================] - 2s 254us/step - loss: 0.1518 - acc: 0.9569 - val_loss: 1.0250 - val_acc: 0.8042\n",
      "Epoch 9/10\n",
      "8083/8083 [==============================] - 2s 243us/step - loss: 0.1365 - acc: 0.9588 - val_loss: 1.0851 - val_acc: 0.7909\n",
      "Epoch 10/10\n",
      "8083/8083 [==============================] - 2s 245us/step - loss: 0.1287 - acc: 0.9566 - val_loss: 1.1015 - val_acc: 0.7909\n",
      "2246/2246 [==============================] - 0s 141us/step\n",
      "Test loss: 1.0850332953095543\n",
      "Test accuracy: 0.7956366874974218\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1)\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
