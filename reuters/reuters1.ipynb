{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import reuters\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv1D, Flatten, Dropout, Input\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  [1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "Training label:  3\n",
      "Length of training data 8982\n",
      "Length of test data 2246\n"
     ]
    }
   ],
   "source": [
    "#Look at a small part of the data\n",
    "print('Training data: ', x_train[0])\n",
    "print('Training label: ', y_train[0])\n",
    "print('Length of training data', len(x_train))\n",
    "print('Length of test data', len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13074"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "#Check to see what index the word sport is, a rudimentary test of the index loading\n",
    "word_index[\"sport\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word at index 13074 is:  sport\n",
      "There are 30980 words in the word index\n"
     ]
    }
   ],
   "source": [
    "#The index is organized to look up the integer value, it would be better to look up the key\n",
    "integer_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# Now we can search for the word that aligns to a certain key, we looked up sport before so lets check that index\n",
    "print('The word at index 13074 is: ',integer_word_index[13074])\n",
    "\n",
    "#how many different words are in the index\n",
    "print('There are', len(integer_word_index)+1, 'words in the word index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "10000\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "#Max words in an article\n",
    "max_words = 10000\n",
    "#46 labels\n",
    "LABEL_DIMENSIONS = max(y_train)+1\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, LABEL_DIMENSIONS)\n",
    "y_test = keras.utils.to_categorical(y_test, LABEL_DIMENSIONS)\n",
    "\n",
    "print(x_train[0])\n",
    "print(len(x_train[0]))\n",
    "\n",
    "print(y_train[0])\n",
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(keep_prob=0.5, optimizer='adam'):\n",
    "    inputs = Input(shape=[10000,], name=\"input\") \n",
    "    \n",
    "    #Convolution 1\n",
    "    conv1 = Dense(64, activation=\"relu\", name=\"conv_1\")(inputs)\n",
    "\n",
    "    #Convolution 2\n",
    "    conv2 = Dense(64,  activation=\"relu\", name=\"conv_2\")(conv1)\n",
    "    \n",
    "    #output\n",
    "    prediction=Dense(46, activation=\"softmax\", name =\"softmax\")(conv2)\n",
    "\n",
    "    # finalize and compile\n",
    "    model = Model(inputs=inputs, outputs=prediction)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hyperparameters():\n",
    "    batches=[10,20,30,40,50,60,70]\n",
    "    optimizers = ['rmsprop','adam','adadelta']\n",
    "    dropout=np.linspace(0.1,0.5,5)\n",
    "    epochs = [5]\n",
    "    return {\"batch_size\":batches, \"optimizer\":optimizers, \"keep_prob\":dropout, \"epochs\":epochs,}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
    "hyperparameters=create_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(estimator=model, param_distributions=hyperparameters, n_iter=10, n_jobs=1, cv=3, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 3s 531us/step - loss: 1.6681 - acc: 0.6431\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 457us/step - loss: 0.8855 - acc: 0.8043\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 3s 472us/step - loss: 0.6025 - acc: 0.8617\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 3s 476us/step - loss: 0.4271 - acc: 0.9061\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 3s 460us/step - loss: 0.3189 - acc: 0.9314\n",
      "2994/2994 [==============================] - 1s 178us/step\n",
      "5988/5988 [==============================] - 1s 151us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 3s 522us/step - loss: 1.6948 - acc: 0.6259\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 462us/step - loss: 0.9346 - acc: 0.7887\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 3s 536us/step - loss: 0.6383 - acc: 0.8584\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 3s 507us/step - loss: 0.4576 - acc: 0.9010\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 3s 473us/step - loss: 0.3376 - acc: 0.9289\n",
      "2994/2994 [==============================] - 1s 189us/step\n",
      "5988/5988 [==============================] - 1s 153us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 3s 531us/step - loss: 1.6829 - acc: 0.6249\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 529us/step - loss: 0.9363 - acc: 0.7861\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 3s 513us/step - loss: 0.6401 - acc: 0.8559\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 3s 497us/step - loss: 0.4477 - acc: 0.9010\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 3s 473us/step - loss: 0.3299 - acc: 0.9305\n",
      "2994/2994 [==============================] - 1s 209us/step\n",
      "5988/5988 [==============================] - 1s 155us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 10s 2ms/step - loss: 1.4249 - acc: 0.6829: 1s - loss: 1.4\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 9s 1ms/step - loss: 0.5518 - acc: 0.8737\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 9s 2ms/step - loss: 0.2543 - acc: 0.9412\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 9s 1ms/step - loss: 0.1759 - acc: 0.9589\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 9s 1ms/step - loss: 0.1406 - acc: 0.9628\n",
      "2994/2994 [==============================] - 1s 267us/step\n",
      "5988/5988 [==============================] - 1s 202us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 10s 2ms/step - loss: 1.3946 - acc: 0.6944\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 9s 1ms/step - loss: 0.5357 - acc: 0.8786\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 9s 2ms/step - loss: 0.2527 - acc: 0.9412\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 9s 1ms/step - loss: 0.1789 - acc: 0.9593\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 9s 1ms/step - loss: 0.1472 - acc: 0.9616\n",
      "2994/2994 [==============================] - 1s 255us/step\n",
      "5988/5988 [==============================] - 1s 206us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 10s 2ms/step - loss: 1.4229 - acc: 0.6885\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 9s 1ms/step - loss: 0.5608 - acc: 0.8712\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 9s 2ms/step - loss: 0.2554 - acc: 0.9449\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 9s 1ms/step - loss: 0.1776 - acc: 0.9601\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 9s 2ms/step - loss: 0.1386 - acc: 0.9638\n",
      "2994/2994 [==============================] - 1s 260us/step\n",
      "5988/5988 [==============================] - 1s 201us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 1.4761 - acc: 0.6723\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 6s 946us/step - loss: 0.8486 - acc: 0.8061\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 6s 955us/step - loss: 0.5818 - acc: 0.8651\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 6s 979us/step - loss: 0.4087 - acc: 0.9138\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 6s 945us/step - loss: 0.2989 - acc: 0.9357\n",
      "2994/2994 [==============================] - 1s 263us/step\n",
      "5988/5988 [==============================] - 1s 201us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 1.5034 - acc: 0.6590\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 6s 926us/step - loss: 0.8658 - acc: 0.8053\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 6s 964us/step - loss: 0.5865 - acc: 0.8707\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 6s 990us/step - loss: 0.4098 - acc: 0.9115\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 6s 936us/step - loss: 0.2962 - acc: 0.9359\n",
      "2994/2994 [==============================] - 1s 271us/step\n",
      "5988/5988 [==============================] - 1s 204us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 1.5186 - acc: 0.6478\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 6s 929us/step - loss: 0.8700 - acc: 0.8023\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 6s 984us/step - loss: 0.5899 - acc: 0.8689\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 6s 957us/step - loss: 0.4090 - acc: 0.9105\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 5s 887us/step - loss: 0.2975 - acc: 0.9372\n",
      "2994/2994 [==============================] - 1s 288us/step\n",
      "5988/5988 [==============================] - 1s 207us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 5s 815us/step - loss: 1.5520 - acc: 0.6486\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 4s 700us/step - loss: 0.8730 - acc: 0.7964\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 4s 692us/step - loss: 0.5885 - acc: 0.8637\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 4s 714us/step - loss: 0.4089 - acc: 0.9107\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 4s 751us/step - loss: 0.3053 - acc: 0.9335\n",
      "2994/2994 [==============================] - 1s 327us/step\n",
      "5988/5988 [==============================] - 1s 210us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 6s 930us/step - loss: 1.5766 - acc: 0.6558\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 5s 804us/step - loss: 0.8797 - acc: 0.7956\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 5s 752us/step - loss: 0.5848 - acc: 0.8682\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 4s 733us/step - loss: 0.4066 - acc: 0.9137\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 5s 752us/step - loss: 0.3007 - acc: 0.9344\n",
      "2994/2994 [==============================] - 1s 320us/step\n",
      "5988/5988 [==============================] - 2s 268us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 6s 954us/step - loss: 1.5653 - acc: 0.6466\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 5s 752us/step - loss: 0.8630 - acc: 0.8033\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 5s 777us/step - loss: 0.5820 - acc: 0.8696\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 5s 760us/step - loss: 0.4057 - acc: 0.9115\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 5s 771us/step - loss: 0.2991 - acc: 0.9355\n",
      "2994/2994 [==============================] - 1s 306us/step\n",
      "5988/5988 [==============================] - 1s 212us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 5s 839us/step - loss: 1.7008 - acc: 0.6249\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 539us/step - loss: 0.9262 - acc: 0.7907\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 3s 520us/step - loss: 0.6297 - acc: 0.8549\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 3s 484us/step - loss: 0.4481 - acc: 0.9011\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 4s 590us/step - loss: 0.3289 - acc: 0.9285\n",
      "2994/2994 [==============================] - 1s 275us/step\n",
      "5988/5988 [==============================] - 1s 190us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 4s 674us/step - loss: 1.7343 - acc: 0.6050\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 525us/step - loss: 0.9457 - acc: 0.7896\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 3s 497us/step - loss: 0.6334 - acc: 0.8629\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5988/5988 [==============================] - 3s 528us/step - loss: 0.4424 - acc: 0.9036\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 3s 509us/step - loss: 0.3208 - acc: 0.9310\n",
      "2994/2994 [==============================] - 1s 259us/step\n",
      "5988/5988 [==============================] - 1s 158us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 4s 663us/step - loss: 1.6838 - acc: 0.6324\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 551us/step - loss: 0.9311 - acc: 0.7894\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 3s 550us/step - loss: 0.6444 - acc: 0.8545\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 3s 534us/step - loss: 0.4603 - acc: 0.8981\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 3s 492us/step - loss: 0.3366 - acc: 0.9285\n",
      "2994/2994 [==============================] - 1s 261us/step\n",
      "5988/5988 [==============================] - 1s 166us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 8s 1ms/step - loss: 1.4405 - acc: 0.6860\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 0.8326 - acc: 0.8136\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 0.5761 - acc: 0.8699\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 0.4206 - acc: 0.9097\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 0.3203 - acc: 0.9324\n",
      "2994/2994 [==============================] - 1s 372us/step\n",
      "5988/5988 [==============================] - 1s 244us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 8s 1ms/step - loss: 1.4402 - acc: 0.6897\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 0.8104 - acc: 0.8250\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 0.5482 - acc: 0.8859\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 8s 1ms/step - loss: 0.4052 - acc: 0.9168\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 8s 1ms/step - loss: 0.3217 - acc: 0.9327\n",
      "2994/2994 [==============================] - 1s 338us/step\n",
      "5988/5988 [==============================] - 1s 228us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 9s 2ms/step - loss: 1.4562 - acc: 0.6785\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 9s 1ms/step - loss: 0.8387 - acc: 0.8238\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 8s 1ms/step - loss: 0.5746 - acc: 0.8796\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 0.4140 - acc: 0.9142\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 0.3228 - acc: 0.9335\n",
      "2994/2994 [==============================] - 1s 325us/step\n",
      "5988/5988 [==============================] - 1s 220us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 4s 602us/step - loss: 1.8379 - acc: 0.6017\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 499us/step - loss: 0.8280 - acc: 0.8115\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 3s 516us/step - loss: 0.4460 - acc: 0.9063\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 3s 491us/step - loss: 0.2714 - acc: 0.9449\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 3s 481us/step - loss: 0.1900 - acc: 0.9596\n",
      "2994/2994 [==============================] - 1s 350us/step\n",
      "5988/5988 [==============================] - 1s 173us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 5s 803us/step - loss: 1.8424 - acc: 0.6216\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 4s 658us/step - loss: 0.8454 - acc: 0.8076\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 3s 581us/step - loss: 0.4593 - acc: 0.9040\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 3s 430us/step - loss: 0.2820 - acc: 0.9409\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 3s 520us/step - loss: 0.2045 - acc: 0.9539\n",
      "2994/2994 [==============================] - 1s 265us/step\n",
      "5988/5988 [==============================] - 1s 168us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 4s 615us/step - loss: 1.8696 - acc: 0.5895\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 450us/step - loss: 0.8490 - acc: 0.8198\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 3s 496us/step - loss: 0.4484 - acc: 0.9080\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 3s 443us/step - loss: 0.2602 - acc: 0.9491\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 3s 452us/step - loss: 0.1860 - acc: 0.9629\n",
      "2994/2994 [==============================] - 1s 322us/step\n",
      "5988/5988 [==============================] - 1s 188us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 5s 758us/step - loss: 1.8825 - acc: 0.6087\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 521us/step - loss: 0.8465 - acc: 0.8098\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 3s 423us/step - loss: 0.4557 - acc: 0.9040\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 3s 506us/step - loss: 0.2668 - acc: 0.9451\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 3s 523us/step - loss: 0.1972 - acc: 0.9574\n",
      "2994/2994 [==============================] - 1s 333us/step\n",
      "5988/5988 [==============================] - 1s 157us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 4s 652us/step - loss: 1.8994 - acc: 0.6099\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 578us/step - loss: 0.8622 - acc: 0.8135\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 3s 519us/step - loss: 0.4669 - acc: 0.9046\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 3s 526us/step - loss: 0.2696 - acc: 0.9457\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 3s 453us/step - loss: 0.1928 - acc: 0.9569\n",
      "2994/2994 [==============================] - 1s 324us/step\n",
      "5988/5988 [==============================] - 1s 182us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 4s 667us/step - loss: 1.9381 - acc: 0.6014\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 474us/step - loss: 0.8268 - acc: 0.8165\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 3s 464us/step - loss: 0.4511 - acc: 0.9070\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 3s 467us/step - loss: 0.2648 - acc: 0.9469\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 3s 485us/step - loss: 0.1893 - acc: 0.9611\n",
      "2994/2994 [==============================] - 1s 441us/step\n",
      "5988/5988 [==============================] - 1s 204us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 4s 587us/step - loss: 1.7467 - acc: 0.6268\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 472us/step - loss: 0.9644 - acc: 0.7811\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 2s 380us/step - loss: 0.6642 - acc: 0.8495\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 2s 390us/step - loss: 0.4666 - acc: 0.9003\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 2s 368us/step - loss: 0.3461 - acc: 0.9259\n",
      "2994/2994 [==============================] - 1s 279us/step\n",
      "5988/5988 [==============================] - 1s 147us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 4s 606us/step - loss: 1.7846 - acc: 0.6114\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 481us/step - loss: 0.9852 - acc: 0.7782\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 2s 395us/step - loss: 0.6724 - acc: 0.8532\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 2s 378us/step - loss: 0.4745 - acc: 0.8966\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 2s 389us/step - loss: 0.3487 - acc: 0.9220\n",
      "2994/2994 [==============================] - 1s 284us/step\n",
      "5988/5988 [==============================] - 1s 140us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 4s 591us/step - loss: 1.8305 - acc: 0.5910\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 3s 451us/step - loss: 0.9780 - acc: 0.7847\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 2s 389us/step - loss: 0.6655 - acc: 0.8512\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 2s 395us/step - loss: 0.4599 - acc: 0.8995 \n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 2s 396us/step - loss: 0.3350 - acc: 0.9287\n",
      "2994/2994 [==============================] - 1s 285us/step\n",
      "5988/5988 [==============================] - 1s 142us/step\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5988/5988 [==============================] - 8s 1ms/step - loss: 1.5874 - acc: 0.6520\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 5s 866us/step - loss: 0.6608 - acc: 0.8552\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 6s 975us/step - loss: 0.3152 - acc: 0.9335\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 6s 933us/step - loss: 0.1981 - acc: 0.9567\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 6s 929us/step - loss: 0.1550 - acc: 0.9613\n",
      "2994/2994 [==============================] - 1s 433us/step\n",
      "5988/5988 [==============================] - 2s 330us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 1.5740 - acc: 0.6710\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 6s 1ms/step - loss: 0.6209 - acc: 0.8621\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 6s 1ms/step - loss: 0.3093 - acc: 0.9305\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 0.1999 - acc: 0.9542\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 6s 979us/step - loss: 0.1617 - acc: 0.9609\n",
      "2994/2994 [==============================] - 1s 473us/step\n",
      "5988/5988 [==============================] - 1s 242us/step\n",
      "Epoch 1/5\n",
      "5988/5988 [==============================] - 7s 1ms/step - loss: 1.5831 - acc: 0.6668\n",
      "Epoch 2/5\n",
      "5988/5988 [==============================] - 6s 983us/step - loss: 0.6582 - acc: 0.8575\n",
      "Epoch 3/5\n",
      "5988/5988 [==============================] - 5s 918us/step - loss: 0.3210 - acc: 0.9362\n",
      "Epoch 4/5\n",
      "5988/5988 [==============================] - 5s 883us/step - loss: 0.2047 - acc: 0.9584\n",
      "Epoch 5/5\n",
      "5988/5988 [==============================] - 6s 925us/step - loss: 0.1594 - acc: 0.9619\n",
      "2994/2994 [==============================] - 1s 429us/step\n",
      "5988/5988 [==============================] - 1s 228us/step\n",
      "Epoch 1/5\n",
      "8982/8982 [==============================] - 6s 664us/step - loss: 1.6649 - acc: 0.6473\n",
      "Epoch 2/5\n",
      "8982/8982 [==============================] - 4s 479us/step - loss: 0.7291 - acc: 0.8410\n",
      "Epoch 3/5\n",
      "8982/8982 [==============================] - 5s 505us/step - loss: 0.3998 - acc: 0.9135\n",
      "Epoch 4/5\n",
      "8982/8982 [==============================] - 5s 508us/step - loss: 0.2570 - acc: 0.9429\n",
      "Epoch 5/5\n",
      "8982/8982 [==============================] - 4s 483us/step - loss: 0.2116 - acc: 0.9460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000001943DA03208>,\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'batch_size': [10, 20, 30, 40, 50, 60, 70], 'optimizer': ['rmsprop', 'adam', 'adadelta'], 'keep_prob': array([0.1, 0.2, 0.3, 0.4, 0.5]), 'epochs': [5]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer': 'adam', 'keep_prob': 0.30000000000000004, 'epochs': 5, 'batch_size': 50}\n"
     ]
    }
   ],
   "source": [
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 64)                640064    \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(10000, )))\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(LABEL_DIMENSIONS, activation=tf.nn.softmax))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 4s 524us/step - loss: 1.7334 - acc: 0.6248 - val_loss: 1.1625 - val_acc: 0.7446\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 2s 291us/step - loss: 0.7969 - acc: 0.8227 - val_loss: 0.9353 - val_acc: 0.7924\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 2s 292us/step - loss: 0.4191 - acc: 0.9120 - val_loss: 0.9477 - val_acc: 0.7969\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 2s 311us/step - loss: 0.2655 - acc: 0.9454 - val_loss: 0.9549 - val_acc: 0.7991\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 2s 329us/step - loss: 0.1990 - acc: 0.9550 - val_loss: 0.9890 - val_acc: 0.7896\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 2s 304us/step - loss: 0.1697 - acc: 0.9584 - val_loss: 1.0124 - val_acc: 0.7913\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 2s 304us/step - loss: 0.1482 - acc: 0.9592 - val_loss: 1.0771 - val_acc: 0.7908\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 2s 307us/step - loss: 0.1443 - acc: 0.9582 - val_loss: 1.0109 - val_acc: 0.8036\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 2s 308us/step - loss: 0.1363 - acc: 0.9592 - val_loss: 1.0262 - val_acc: 0.7947\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 2s 313us/step - loss: 0.1244 - acc: 0.9596 - val_loss: 1.0681 - val_acc: 0.7980\n",
      "2246/2246 [==============================] - 0s 169us/step\n",
      "Test loss: 1.1264522935223176\n",
      "Test accuracy: 0.7831700795586366\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
