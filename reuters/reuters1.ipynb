{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import reuters\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv1D, Flatten, Dropout, Input\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  [1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "Training label:  3\n",
      "Length of training data 8982\n",
      "Length of test data 2246\n"
     ]
    }
   ],
   "source": [
    "#Look at a small part of the data\n",
    "print('Training data: ', x_train[0])\n",
    "print('Training label: ', y_train[0])\n",
    "print('Length of training data', len(x_train))\n",
    "print('Length of test data', len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13074"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "#Check to see what index the word sport is, a rudimentary test of the index loading\n",
    "word_index[\"sport\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word at index 13074 is:  sport\n",
      "There are 30980 words in the word index\n"
     ]
    }
   ],
   "source": [
    "#The index is organized to look up the integer value, it would be better to look up the key\n",
    "integer_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# Now we can search for the word that aligns to a certain key, we looked up sport before so lets check that index\n",
    "print('The word at index 13074 is: ',integer_word_index[13074])\n",
    "\n",
    "#how many different words are in the index\n",
    "print('There are', len(integer_word_index)+1, 'words in the word index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "10000\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "#Max words in an article\n",
    "max_words = 10000\n",
    "#46 labels\n",
    "LABEL_DIMENSIONS = max(y_train)+1\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, LABEL_DIMENSIONS)\n",
    "y_test = keras.utils.to_categorical(y_test, LABEL_DIMENSIONS)\n",
    "\n",
    "print(x_train[0])\n",
    "print(len(x_train[0]))\n",
    "\n",
    "print(y_train[0])\n",
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(keep_prob=0.5, optimizer='adam'):\n",
    "    inputs = Input(shape=[10000,], name=\"input\") \n",
    "    \n",
    "    #Convolution 1\n",
    "    conv1 = Dense(128, activation=\"relu\", name=\"conv_1\")(inputs)\n",
    "\n",
    "    #Convolution 2\n",
    "    conv2 = Dense(64,  activation=\"relu\", name=\"conv_2\")(conv1)\n",
    "   \n",
    "    #output\n",
    "    prediction=Dense(46, activation=\"softmax\", name =\"softmax\")(conv2)\n",
    "\n",
    "    # finalize and compile\n",
    "    model = Model(inputs=inputs, outputs=prediction)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hyperparameters():\n",
    "    batches=[10,20,30,40,50,60,70]\n",
    "    optimizers = ['rmsprop','adam','adadelta']\n",
    "    dropout=np.linspace(0.1,0.5,5)\n",
    "    epochs = [5]\n",
    "    return {\"batch_size\":batches, \"optimizer\":optimizers, \"keep_prob\":dropout, \"epochs\":epochs,}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=build_model, verbose=2)\n",
    "hyperparameters=create_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(estimator=model, param_distributions=hyperparameters, n_iter=10, n_jobs=1, cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] optimizer=adadelta, keep_prob=0.4, epochs=5, batch_size=10 ......\n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.3778 - acc: 0.6894\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.7581 - acc: 0.8282\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.4742 - acc: 0.8901\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.3135 - acc: 0.9324\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.2348 - acc: 0.9484\n",
      "[CV]  optimizer=adadelta, keep_prob=0.4, epochs=5, batch_size=10, total=  22.1s\n",
      "[CV] optimizer=adadelta, keep_prob=0.4, epochs=5, batch_size=10 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 6s - loss: 1.3834 - acc: 0.6899\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.7583 - acc: 0.8333\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.4798 - acc: 0.8993\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.3273 - acc: 0.9307\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.2427 - acc: 0.9471\n",
      "[CV]  optimizer=adadelta, keep_prob=0.4, epochs=5, batch_size=10, total=  22.2s\n",
      "[CV] optimizer=adadelta, keep_prob=0.4, epochs=5, batch_size=10 ......\n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.3946 - acc: 0.6830\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.7481 - acc: 0.8267\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.4786 - acc: 0.8925\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.3156 - acc: 0.9304\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.2335 - acc: 0.9471\n",
      "[CV]  optimizer=adadelta, keep_prob=0.4, epochs=5, batch_size=10, total=  22.3s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.1, epochs=5, batch_size=50 .......\n",
      "Epoch 1/5\n",
      " - 3s - loss: 1.5078 - acc: 0.6820\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.7199 - acc: 0.8460\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.4159 - acc: 0.9137\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.2671 - acc: 0.9436\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.1978 - acc: 0.9566\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.1, epochs=5, batch_size=50, total=   7.6s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.1, epochs=5, batch_size=50 .......\n",
      "Epoch 1/5\n",
      " - 3s - loss: 1.5418 - acc: 0.6727\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.7418 - acc: 0.8425\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.4260 - acc: 0.9120\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.2864 - acc: 0.9405\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.2069 - acc: 0.9532\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.1, epochs=5, batch_size=50, total=   7.6s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.1, epochs=5, batch_size=50 .......\n",
      "Epoch 1/5\n",
      " - 3s - loss: 1.5475 - acc: 0.6687\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.7361 - acc: 0.8370\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.4243 - acc: 0.9113\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.2654 - acc: 0.9421\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.1922 - acc: 0.9572\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.1, epochs=5, batch_size=50, total=   7.7s\n",
      "[CV] optimizer=adadelta, keep_prob=0.4, epochs=5, batch_size=70 ......\n",
      "Epoch 1/5\n",
      " - 3s - loss: 1.6727 - acc: 0.6361\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.8657 - acc: 0.8041\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.5518 - acc: 0.8783\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.3802 - acc: 0.9178\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.2710 - acc: 0.9444\n",
      "[CV]  optimizer=adadelta, keep_prob=0.4, epochs=5, batch_size=70, total=   7.7s\n",
      "[CV] optimizer=adadelta, keep_prob=0.4, epochs=5, batch_size=70 ......\n",
      "Epoch 1/5\n",
      " - 3s - loss: 1.7221 - acc: 0.6214\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.8790 - acc: 0.8031\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.5652 - acc: 0.8773\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.3827 - acc: 0.9180\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.2782 - acc: 0.9390\n",
      "[CV]  optimizer=adadelta, keep_prob=0.4, epochs=5, batch_size=70, total=   8.2s\n",
      "[CV] optimizer=adadelta, keep_prob=0.4, epochs=5, batch_size=70 ......\n",
      "Epoch 1/5\n",
      " - 3s - loss: 1.6937 - acc: 0.6234\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.8919 - acc: 0.7974\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.5732 - acc: 0.8727\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.3807 - acc: 0.9160\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.2617 - acc: 0.9437\n",
      "[CV]  optimizer=adadelta, keep_prob=0.4, epochs=5, batch_size=70, total=   8.0s\n",
      "[CV] optimizer=adadelta, keep_prob=0.30000000000000004, epochs=5, batch_size=20 \n",
      "Epoch 1/5\n",
      " - 4s - loss: 1.4380 - acc: 0.6743\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.7475 - acc: 0.8277\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.4694 - acc: 0.8968\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.3123 - acc: 0.9320\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.2219 - acc: 0.9522\n",
      "[CV]  optimizer=adadelta, keep_prob=0.30000000000000004, epochs=5, batch_size=20, total=  14.5s\n",
      "[CV] optimizer=adadelta, keep_prob=0.30000000000000004, epochs=5, batch_size=20 \n",
      "Epoch 1/5\n",
      " - 4s - loss: 1.4445 - acc: 0.6692\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.7698 - acc: 0.8235\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.4719 - acc: 0.8963\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.3125 - acc: 0.9300\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.2308 - acc: 0.9502\n",
      "[CV]  optimizer=adadelta, keep_prob=0.30000000000000004, epochs=5, batch_size=20, total=  14.0s\n",
      "[CV] optimizer=adadelta, keep_prob=0.30000000000000004, epochs=5, batch_size=20 \n",
      "Epoch 1/5\n",
      " - 4s - loss: 1.4744 - acc: 0.6677\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.7823 - acc: 0.8195\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.4874 - acc: 0.8920\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.3176 - acc: 0.9325\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.2239 - acc: 0.9512\n",
      "[CV]  optimizer=adadelta, keep_prob=0.30000000000000004, epochs=5, batch_size=20, total=  14.2s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=70 .......\n",
      "Epoch 1/5\n",
      " - 3s - loss: 1.5922 - acc: 0.6593\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.7853 - acc: 0.8322\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.4534 - acc: 0.9058\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.2829 - acc: 0.9400\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.2090 - acc: 0.9546\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=70, total=   7.8s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=70 .......\n",
      "Epoch 1/5\n",
      " - 3s - loss: 1.6016 - acc: 0.6481\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.7747 - acc: 0.8350\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.4538 - acc: 0.9053\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.2882 - acc: 0.9394\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.2106 - acc: 0.9532\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=70, total=   7.5s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=70 .......\n",
      "Epoch 1/5\n",
      " - 3s - loss: 1.6375 - acc: 0.6471\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.7945 - acc: 0.8252\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.4568 - acc: 0.9050\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.2851 - acc: 0.9429\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.2018 - acc: 0.9546\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=70, total=   7.2s\n",
      "[CV] optimizer=adadelta, keep_prob=0.1, epochs=5, batch_size=10 ......\n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.3782 - acc: 0.6882\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.7782 - acc: 0.8208\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.4954 - acc: 0.8883\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.3365 - acc: 0.9282\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.2484 - acc: 0.9442\n",
      "[CV]  optimizer=adadelta, keep_prob=0.1, epochs=5, batch_size=10, total=  23.2s\n",
      "[CV] optimizer=adadelta, keep_prob=0.1, epochs=5, batch_size=10 ......\n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.3783 - acc: 0.6869\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.7687 - acc: 0.8272\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.4873 - acc: 0.8901\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.3256 - acc: 0.9287\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.2435 - acc: 0.9471\n",
      "[CV]  optimizer=adadelta, keep_prob=0.1, epochs=5, batch_size=10, total=  23.2s\n",
      "[CV] optimizer=adadelta, keep_prob=0.1, epochs=5, batch_size=10 ......\n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.4000 - acc: 0.6810\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.7709 - acc: 0.8250\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.4879 - acc: 0.8913\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.3264 - acc: 0.9269\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.2373 - acc: 0.9472\n",
      "[CV]  optimizer=adadelta, keep_prob=0.1, epochs=5, batch_size=10, total=  23.4s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=30 .......\n",
      "Epoch 1/5\n",
      " - 4s - loss: 1.4391 - acc: 0.6882\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.6616 - acc: 0.8497\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.3792 - acc: 0.9205\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.2503 - acc: 0.9447\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.2008 - acc: 0.9569\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=30, total=  10.4s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=30 .......\n",
      "Epoch 1/5\n",
      " - 4s - loss: 1.4460 - acc: 0.6864\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.6964 - acc: 0.8477\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.3986 - acc: 0.9127\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.2685 - acc: 0.9434\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.2060 - acc: 0.9557\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=30, total=  10.5s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=30 .......\n",
      "Epoch 1/5\n",
      " - 4s - loss: 1.4642 - acc: 0.6769\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.6951 - acc: 0.8479\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.3988 - acc: 0.9140\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.2465 - acc: 0.9449\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.1920 - acc: 0.9564\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=30, total=  10.5s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.30000000000000004, epochs=5, batch_size=10 \n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.3519 - acc: 0.7016\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.7236 - acc: 0.8408\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4617 - acc: 0.9003\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3269 - acc: 0.9345\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2612 - acc: 0.9449\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.30000000000000004, epochs=5, batch_size=10, total=  20.8s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.30000000000000004, epochs=5, batch_size=10 \n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.3484 - acc: 0.7059\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.7362 - acc: 0.8459\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4813 - acc: 0.8965\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3539 - acc: 0.9257\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2846 - acc: 0.9444\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.30000000000000004, epochs=5, batch_size=10, total=  20.8s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.30000000000000004, epochs=5, batch_size=10 \n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.3737 - acc: 0.7041\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.7403 - acc: 0.8348\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4793 - acc: 0.8975\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3321 - acc: 0.9284\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2632 - acc: 0.9496\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.30000000000000004, epochs=5, batch_size=10, total=  20.9s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.2, epochs=5, batch_size=10 .......\n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.3516 - acc: 0.7006\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.7304 - acc: 0.8424\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4767 - acc: 0.9001\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3431 - acc: 0.9274\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2678 - acc: 0.9424\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.2, epochs=5, batch_size=10, total=  20.8s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.2, epochs=5, batch_size=10 .......\n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.3624 - acc: 0.7019\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.7394 - acc: 0.8424\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4842 - acc: 0.8935\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3589 - acc: 0.9277\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2885 - acc: 0.9414\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.2, epochs=5, batch_size=10, total=  20.7s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.2, epochs=5, batch_size=10 .......\n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.3689 - acc: 0.6981\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.7334 - acc: 0.8485\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4674 - acc: 0.8980\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3355 - acc: 0.9320\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2648 - acc: 0.9471\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.2, epochs=5, batch_size=10, total=  21.0s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=10 .......\n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.3285 - acc: 0.7103\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.7300 - acc: 0.8437\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4640 - acc: 0.9000\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3411 - acc: 0.9312\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2659 - acc: 0.9489\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=10, total=  20.8s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=10 .......\n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.3633 - acc: 0.6979\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.7253 - acc: 0.8479\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4611 - acc: 0.9021\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3389 - acc: 0.9307\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2667 - acc: 0.9439\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=10, total=  20.9s\n",
      "[CV] optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=10 .......\n",
      "Epoch 1/5\n",
      " - 6s - loss: 1.3899 - acc: 0.6989\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.7484 - acc: 0.8388\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4848 - acc: 0.8960\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.3484 - acc: 0.9228\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.2780 - acc: 0.9421\n",
      "[CV]  optimizer=rmsprop, keep_prob=0.4, epochs=5, batch_size=10, total=  21.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  8.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 8s - loss: 1.2426 - acc: 0.7335\n",
      "Epoch 2/5\n",
      " - 5s - loss: 0.7084 - acc: 0.8476\n",
      "Epoch 3/5\n",
      " - 5s - loss: 0.4950 - acc: 0.8946\n",
      "Epoch 4/5\n",
      " - 5s - loss: 0.3774 - acc: 0.9233\n",
      "Epoch 5/5\n",
      " - 5s - loss: 0.3252 - acc: 0.9353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f52bb67b208>,\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'batch_size': [10, 20, 30, 40, 50, 60, 70], 'optimizer': ['rmsprop', 'adam', 'adadelta'], 'keep_prob': array([0.1, 0.2, 0.3, 0.4, 0.5]), 'epochs': [5]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer': 'rmsprop', 'keep_prob': 0.2, 'epochs': 5, 'batch_size': 10}\n"
     ]
    }
   ],
   "source": [
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1280128   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 1,291,374\n",
      "Trainable params: 1,291,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape=(10000, )))\n",
    "model.add(tf.keras.layers.Dropout(0.8))\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(LABEL_DIMENSIONS, activation=tf.nn.softmax))\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 2s 346us/step - loss: 3.0428 - acc: 0.2788 - val_loss: 1.7043 - val_acc: 0.5899\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 2s 290us/step - loss: 1.6582 - acc: 0.5981 - val_loss: 1.3423 - val_acc: 0.7140\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 2s 311us/step - loss: 1.4033 - acc: 0.6745 - val_loss: 1.2146 - val_acc: 0.7362\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 2s 303us/step - loss: 1.2573 - acc: 0.7105 - val_loss: 1.1408 - val_acc: 0.7535\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 2s 310us/step - loss: 1.1636 - acc: 0.7304 - val_loss: 1.1126 - val_acc: 0.7624\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 2s 304us/step - loss: 1.1079 - acc: 0.7473 - val_loss: 1.0859 - val_acc: 0.7696\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 2s 293us/step - loss: 1.0327 - acc: 0.7621 - val_loss: 1.0576 - val_acc: 0.7824\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 2s 290us/step - loss: 0.9847 - acc: 0.7756 - val_loss: 1.0542 - val_acc: 0.7924\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 2s 289us/step - loss: 0.9440 - acc: 0.7808 - val_loss: 1.0467 - val_acc: 0.7913\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 2s 290us/step - loss: 0.9175 - acc: 0.7971 - val_loss: 1.0353 - val_acc: 0.7991\n",
      "2246/2246 [==============================] - 0s 112us/step\n",
      "Test loss: 1.1112920675602536\n",
      "Test accuracy: 0.7800534290069995\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
